{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae138813",
   "metadata": {},
   "source": [
    "# Tensor operations\n",
    "\n",
    "While implementing attention mechanism I stumbled across abundance of tensor arithmetic that is used in NN-context.\n",
    "This notebook serves one simple purpose: get used to some common operators and patterns used in PyTorch for tensor transformations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca34b983",
   "metadata": {},
   "source": [
    "## Einstein summation notation\n",
    "To use `torch.einsum` it is practical to keep the following in mind:\n",
    "- **Sizes.** while performing einstein summation over tensors, we mark each axis of an input tensor with a label, if the same label appears in multiple tensors definitions, those dimensions must be equal.  \n",
    "  E.g. we want to work with two tensors: `ij, jk->`. The second dimension of the first rank two tensor is equal to the first dimension of the second tensor.\n",
    "- **Reduction.** If the index on the left side occurs twice, or if it is presneted on the left, but not on the right, it means that we sum over this index and it is reduced.  \n",
    "  E.g. `i,i->`.\n",
    "- **Free indices.** Any index that does appear in the output is kept (and dimension is preserved). The labels order defines the output axis order.  \n",
    "  E.g.: `ij,jk->ik`, `ij->ji`.\n",
    "\n",
    "**Intuition**:\n",
    "1. Repeat a label and omit from output - the axis is contracted (summed away).\n",
    "2. List a label in output - the axis is preserved, and placed according to the label order.\n",
    "\n",
    "Interpretation of: `torch.einsum(\"ab,ac->ac\", A, X)`, $A \\in \\mathbb{R}^{a \\times b}$, $B \\in \\mathbb{R}^{a \\times c}$.\n",
    "- Indices: `a` = row, `b` = $A$ column, `c` = $X$ column.\n",
    "- Formula:  \n",
    "  $$\\text{out}_{a c}=\\sum_b A_{a b}\\,X_{a c} =\\big(\\sum_b A_{a b}\\big)\\,X_{a c}.$$\n",
    "- So we sum over `b` and it disappears: row-wise scaling of $X$ by the row sums of $A$.\n",
    "\n",
    "Few more operations:\n",
    "- `ab,ac->bc`, `a` is omitted, we sum over it, So it a matrix product: $\\sum_a A_{ab}X_{ac}$, it is the same as $A^T B$.\n",
    "- `ab,ac->cb`, `a` is omitted, we sum over it. The same as $B^T A$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4c7850",
   "metadata": {},
   "source": [
    "### Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c9efa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Outer product\n",
    "a = torch.randn(3)\n",
    "b = torch.randn(2)\n",
    "torch.einsum(\"i,j->ij\", a, b) # (3,2) \n",
    "\n",
    "# Inner product\n",
    "a = torch.randn(3)  # (3,)\n",
    "b = torch.randn(3)  # (3,)\n",
    "torch.einsum(\"i,i->\", a, b)\n",
    "\n",
    "# Matrix-vector product\n",
    "A = torch.randn(4, 2)\n",
    "b = torch.randn(2)\n",
    "torch.einsum(\"ij,j->i\", A, b) # (4,)\n",
    "\n",
    "# Batch matrix-vector product\n",
    "A = torch.randn(100, 4, 2)\n",
    "B = torch.randn(100, 2)\n",
    "torch.einsum(\"ijk,ik->ij\", A, B) # (100,4) == torch.bmm(A, B.unsqueeze(-1)).squeeze(-1)\n",
    "\n",
    "# Attention score computation\n",
    "Q = torch.randn(100, 32, 15, 64)       # (batch_size, num_heads, seq_len, d_k)\n",
    "K = torch.randn(100, 32, 15, 64)       # (batch_size, num_heads, seq_len, d_k)\n",
    "torch.einsum(\"bhid, bhjd->bhij\", Q, K) # (batch_size, num_heads, seq_len, seq_len) == Q @ K.transpose(-2, -1)\n",
    "\n",
    "# Weighted sum over tokens\n",
    "X = torch.randn(100, 15, 3)\n",
    "w = torch.randn(100, 15)\n",
    "torch.einsum(\"ijk,ij->ik\", X, w);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ff30f8b",
   "metadata": {},
   "source": [
    "## Useful tensor operations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c71396",
   "metadata": {},
   "source": [
    "`squeeze`\n",
    "\n",
    "**What:** removes size-1 dimensions\n",
    "\n",
    "**Shape effect:** drops axes where length == 1.\n",
    "\n",
    "**Examples:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "7f59018c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 3, 1])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 1, 3, 1)\n",
    "x.shape            # (2, 1, 3, 1)\n",
    "x.squeeze().shape  # (2, 3)\n",
    "x.squeeze(1).shape # (2, 3, 1)   # only if dim 1 is size-1 (else unchanged)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fd7b7c",
   "metadata": {},
   "source": [
    "`unsqueeze`\n",
    "\n",
    "**What:** insert a size-1 dimension at a position.\n",
    "\n",
    "**Shape effect:** rank + 1.\n",
    "\n",
    "**Examples:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "958506c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1, 5])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(4, 5)\n",
    "x.shape                # (B, C)\n",
    "x.unsqueeze(1).shape   # (B, 1, C)\n",
    "x[:, None, :].shape    # same as unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6cbb873",
   "metadata": {},
   "source": [
    "`permute`\n",
    "\n",
    "**What:** reoder dimensions (general transpose)\n",
    "\n",
    "**Shape effect:** same sizes, different order; returns a **view**.\n",
    "\n",
    "**Examples:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e7841f6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 4, 3, 12)\n",
    "\n",
    "x.shape                         # (B, H, W, C)\n",
    "x.permute(0, 3, 1, 2).shape     # (B, C, H, W)\n",
    "\n",
    "# Special cases:\n",
    "x.transpose(1, 2) == x.permute(0, 2, 1, 3);  # when ranks match appropriately"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b657d864",
   "metadata": {},
   "source": [
    "`chunk`\n",
    "\n",
    "**What:** split a tensor into N equal parts along a dim\n",
    "\n",
    "**Return:** a tuple of tensors (views when possible)\n",
    "\n",
    "**Gotcha:** if the size is not divisible, some chunks could be larger than others.\n",
    "\n",
    "**Examples:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4be50dbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 4, 12]) torch.Size([5, 4, 12]) torch.Size([5, 2, 12])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(5, 10, 12)\n",
    "x.shape                          # (B, T, 3*D)\n",
    "q, k, v = x.chunk(3, dim=-1)     # (B, T, D) each\n",
    "y1, y2, y3 = x.chunk(3, dim=1)   # split time steps along dim=1\n",
    "print(y1.shape, y2.shape, y3.shape)  # each (B, T/3, 3*D)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d38e10d",
   "metadata": {},
   "source": [
    "`.contigious()`\n",
    "\n",
    "**What:** ensure memory is laid out contiguously (needed for .view).\n",
    "\n",
    "**Shape:** unchanged.\n",
    "\n",
    "**Gotcha:** may allocate/copy. Check `.is_contiguous()`\n",
    "\n",
    "**Examples:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d451f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x.permute(0,2,1)           # likely non-contiguous\n",
    "z = y.contiguous().view(1, -1) # OK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b866e840",
   "metadata": {},
   "source": [
    "`torch.flatten(x, start_dim=0, end_dim=-1)`\n",
    "\n",
    "**What:** merge a dim range into one.\n",
    "\n",
    "**Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "be7fc65d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 60])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3, 4, 5)\n",
    "y = torch.flatten(x, start_dim=1, end_dim=-1)\n",
    "y.shape  # (2, 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c433b3",
   "metadata": {},
   "source": [
    "`torch.cat()` and `torch.stack()`\n",
    "\n",
    "**What:** **concat** along an **existing** axis or **stack** along a **new** one\n",
    "\n",
    "**Example**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70cc097f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 6]), torch.Size([2, 3, 2]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(2, 3)\n",
    "y = torch.randn(2, 3)\n",
    "\n",
    "z_cat = torch.cat([x, y], dim=1)   # (2, 6)\n",
    "z_stack = torch.stack([x, y], dim=2) # (2, 3, 2)\n",
    "z_cat.shape, z_stack.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf588e07",
   "metadata": {},
   "source": [
    "`x.unbind(dim=0)`\n",
    "\n",
    "**What:** split into tuple of slices **removing** that dim.\n",
    "\n",
    "**Example:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "c11b1897",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 3, 4)\n",
    "a, b, c = x.unbind(dim=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learning-ai-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
